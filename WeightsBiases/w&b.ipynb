{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1705274</td>\n",
       "      <td>2024-11-01T12:53:19+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1705273</td>\n",
       "      <td>2024-11-01T12:52:29+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1705272</td>\n",
       "      <td>2024-11-01T12:48:24+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>المنشية تواجد جيش مع شرطة ومخالفات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705271</td>\n",
       "      <td>2024-11-01T12:44:55+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>الرجاء من كل شخص بقرا التقرير يكبس ❤️ أو 👍\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1705270</td>\n",
       "      <td>2024-11-01T12:39:22+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>تم فتح حاجز عناب الان بالاتجاهين ✅✅✅✅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       date     sender_id  \\\n",
       "0  1705274  2024-11-01T12:53:19+00:00  6.415259e+09   \n",
       "1  1705273  2024-11-01T12:52:29+00:00  6.415259e+09   \n",
       "2  1705272  2024-11-01T12:48:24+00:00  6.415259e+09   \n",
       "3  1705271  2024-11-01T12:44:55+00:00  6.415259e+09   \n",
       "4  1705270  2024-11-01T12:39:22+00:00  6.415259e+09   \n",
       "\n",
       "                                             message  \n",
       "0                                 شرطه نازله من عيلي  \n",
       "1               حادث سير بعد اشارات شيلو باتجاه عيلي  \n",
       "2                 المنشية تواجد جيش مع شرطة ومخالفات  \n",
       "3  الرجاء من كل شخص بقرا التقرير يكبس ❤️ أو 👍\\n\\n...  \n",
       "4              تم فتح حاجز عناب الان بالاتجاهين ✅✅✅✅  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/mac2/University/Machine Learning/VS Code /Test_repo/ROADWATCH/Road/messages_cleanedNEW.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1705274</td>\n",
       "      <td>2024-11-01T12:53:19+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1705273</td>\n",
       "      <td>2024-11-01T12:52:29+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1705272</td>\n",
       "      <td>2024-11-01T12:48:24+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>المنشية تواجد جيش مع شرطة ومخالفات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705271</td>\n",
       "      <td>2024-11-01T12:44:55+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>الرجاء من كل شخص بقرا التقرير يكبس  أو \\n\\nتفا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1705270</td>\n",
       "      <td>2024-11-01T12:39:22+00:00</td>\n",
       "      <td>6.415259e+09</td>\n",
       "      <td>تم فتح حاجز عناب الان بالاتجاهين</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       date     sender_id  \\\n",
       "0  1705274  2024-11-01T12:53:19+00:00  6.415259e+09   \n",
       "1  1705273  2024-11-01T12:52:29+00:00  6.415259e+09   \n",
       "2  1705272  2024-11-01T12:48:24+00:00  6.415259e+09   \n",
       "3  1705271  2024-11-01T12:44:55+00:00  6.415259e+09   \n",
       "4  1705270  2024-11-01T12:39:22+00:00  6.415259e+09   \n",
       "\n",
       "                                             message  \n",
       "0                                 شرطه نازله من عيلي  \n",
       "1               حادث سير بعد اشارات شيلو باتجاه عيلي  \n",
       "2                 المنشية تواجد جيش مع شرطة ومخالفات  \n",
       "3  الرجاء من كل شخص بقرا التقرير يكبس  أو \\n\\nتفا...  \n",
       "4                  تم فتح حاجز عناب الان بالاتجاهين   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emojis(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'[^\\w\\s,.!?؛:\\n]', '', text)\n",
    "    return text\n",
    "\n",
    "data['message'] = data['message'].apply(remove_emojis)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_jargon(data, jargon_terms):\n",
    "    def clean_message(message):\n",
    "        pattern = re.compile(r'\\b(' + '|'.join(re.escape(term) for term in jargon_terms) + r')\\b', re.IGNORECASE)\n",
    "        return pattern.sub('', message)\n",
    "\n",
    "    data['message'] = data['message'].apply(clean_message)\n",
    "    data['message'] = data['message'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Original Message</th>\n",
       "      <th>Word Index</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شرطه</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نازله</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>من</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عيلي</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حادث</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303763</th>\n",
       "      <td>وتفتيش</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>6</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303764</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>7</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303765</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>8</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303766</th>\n",
       "      <td>عورتا</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>1</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303767</th>\n",
       "      <td>لداخل</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>2</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303768 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word                                   Original Message  Word Index  \\\n",
       "0         شرطه                                 شرطه نازله من عيلي           1   \n",
       "1        نازله                                 شرطه نازله من عيلي           2   \n",
       "2           من                                 شرطه نازله من عيلي           3   \n",
       "3         عيلي                                 شرطه نازله من عيلي           4   \n",
       "4         حادث               حادث سير بعد اشارات شيلو باتجاه عيلي           1   \n",
       "...        ...                                                ...         ...   \n",
       "303763  وتفتيش  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           6   \n",
       "303764   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           7   \n",
       "303765   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           8   \n",
       "303766   عورتا                                        عورتا لداخل           1   \n",
       "303767   لداخل                                        عورتا لداخل           2   \n",
       "\n",
       "       Sentence Message  \n",
       "0             1       0  \n",
       "1             1       0  \n",
       "2             1       0  \n",
       "3             1       0  \n",
       "4             2       1  \n",
       "...         ...     ...  \n",
       "303763    32976   33988  \n",
       "303764    32976   33988  \n",
       "303765    32976   33988  \n",
       "303766    32977   33990  \n",
       "303767    32977   33990  \n",
       "\n",
       "[303768 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regex_tokenize(data):\n",
    "    sentence_splitter = re.compile(r'(?<=[.!?]) +')\n",
    "    word_splitter = re.compile(r'[\\u0600-\\u06FF]+|\\d+|\\w+')\n",
    "\n",
    "    sentences_list = []\n",
    "    words_list = []\n",
    "    original_messages = []\n",
    "    word_indices = []\n",
    "    sentence_count = 1\n",
    "\n",
    "    for index, message in data['message'].items():\n",
    "        if isinstance(message, str):\n",
    "            sentences = sentence_splitter.split(message.strip())\n",
    "            for sentence in sentences:\n",
    "                words = word_splitter.findall(sentence)\n",
    "                for word_index, word in enumerate(words):\n",
    "                    sentences_list.append(f\"Sentence: {sentence_count} (Message {index})\")\n",
    "                    words_list.append(word)\n",
    "                    original_messages.append(message)\n",
    "                    word_indices.append(word_index + 1)\n",
    "                sentence_count += 1\n",
    "        \n",
    "    tokenized_df = pd.DataFrame({\n",
    "        'Sentence #': sentences_list,\n",
    "        'Word': words_list,\n",
    "        'Original Message': original_messages,\n",
    "        'Word Index': word_indices\n",
    "    })\n",
    "\n",
    "    return tokenized_df\n",
    "\n",
    "tokenized_df = regex_tokenize(data)\n",
    "tokenized_df[['Sentence', 'Message']] = tokenized_df['Sentence #'].str.extract(r'Sentence: (\\d+) \\(Message (\\d+)\\)')\n",
    "tokenized_df.drop(columns=['Sentence #'], inplace=True)\n",
    "tokenized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Original Message</th>\n",
       "      <th>Word Index</th>\n",
       "      <th>label</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شرطه</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نازله</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>من</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عيلي</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>4</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حادث</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303763</th>\n",
       "      <td>وتفتيش</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>6</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303764</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>7</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303765</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>8</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303766</th>\n",
       "      <td>عورتا</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>1</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303767</th>\n",
       "      <td>لداخل</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303768 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word                                   Original Message  Word Index  \\\n",
       "0         شرطه                                 شرطه نازله من عيلي           1   \n",
       "1        نازله                                 شرطه نازله من عيلي           2   \n",
       "2           من                                 شرطه نازله من عيلي           3   \n",
       "3         عيلي                                 شرطه نازله من عيلي           4   \n",
       "4         حادث               حادث سير بعد اشارات شيلو باتجاه عيلي           1   \n",
       "...        ...                                                ...         ...   \n",
       "303763  وتفتيش  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           6   \n",
       "303764   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           7   \n",
       "303765   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           8   \n",
       "303766   عورتا                                        عورتا لداخل           1   \n",
       "303767   لداخل                                        عورتا لداخل           2   \n",
       "\n",
       "        label  Similarity Score Sentence Message  \n",
       "0           O               0.0        1       0  \n",
       "1           O               0.0        1       0  \n",
       "2           O               0.0        1       0  \n",
       "3       B-LOC             100.0        1       0  \n",
       "4           O               0.0        2       1  \n",
       "...       ...               ...      ...     ...  \n",
       "303763      O               0.0    32976   33988  \n",
       "303764      O               0.0    32976   33988  \n",
       "303765      O               0.0    32976   33988  \n",
       "303766  B-LOC             100.0    32977   33990  \n",
       "303767      O               0.0    32977   33990  \n",
       "\n",
       "[303768 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "location_names = [\n",
    "    \"المنشية\", \"يتسهار\", \"صرة\", \"زعترة\", \"عصيرة\", \"المساكن\", \"المربعة\", \n",
    "    \"بوابة بورين\", \"دير شرف\", \"عورتا\", \"بيت فوريك\", \"بزاريا\", \"شافي شمرون\",\n",
    "    \"حومش\", \"عناب\", \"الكفريات\", \"حجة\", \"وادي قانا\", \"بيت ليد\", \"كفر لاقف\", \n",
    "    \"الحمرا\", \"عوفرا\", \"ارئيل\", \"سلفيت\", \"رام الله\", \"نابلس\", \"عين سينيا\", \n",
    "    \"عطارة\", \"روابي\", \"عيون الحرامية\", \"ترمسعيا\", \"سنجل\", \"كركر\", \"بيت ايل\", \n",
    "    \"عزون\", \"جماعين\", \"كفل حارس\", \"مردا\", \"اللبن الشرقية\", \"بديا\", \"برقين\", \n",
    "    \"الزعيم\", \"العيزرية\", \"قلنديا\", \"جبع\", \"الكونتينر\", \"عش الغراب\", \n",
    "    \"مخماس\", \"جيت\", \"بيتا\", \"دير بلوط\", \"ياسوف\", \"النبي الياس\", \"سعير\", \n",
    "    \"حلحول\", \"حوارة\", \"راس الجورة\", \"عناتا\", \"حزما\", \"اماتين\", \"بيرزيت\", \n",
    "    \"النبي صالح\", \"افرات\", \"تقوع\", \"دورا\", \"عتصيون\", \"العروب\", \"فرش الهوى\", \n",
    "    \"حاجز النفق\", \"شارع بيجن\", \"الخليل\", \"واد النار\", \"DCO\", \"بيت جالا\", \n",
    "    \"اريحا\", \"برقة\", \"الغرس\", \"يتما\", \"الساوية\", \"يبرود\", \"سلواد\", \n",
    "    \"الطيبة\", \"النشاش\", \"طولكرم\", \"المسعودية\", \"بيت ايل\", \"جنين\", \n",
    "    \"قلقيلية\", \"عيلي\", \"كدوميم\", \"مخيم الجلزون\", \"روجيب\", \"شعفاط\", \n",
    "    \"الرام\", \"بيت لحم\", \"حوارة\", \"قبلان\", \"عينبوس\", \"بيت عور\", \"القرع\", \n",
    "    \"اودلا\", \"معالي ادوميم\", \"حزما\", \"السيلة\", \"نور شمس\", \"بلعا\", \n",
    "    \"الجفتلك\", \"الباذان\", \"البيرة\", \"بركان\", \"حبلة\", \"حرميش\", \"طوباس\", \n",
    "    \"السيلة\", \"افرايم\", \"ضواحي القدس\", \"القدس\", \"العبيدية\", \"بيت ساحور\", \n",
    "    \"تل الربيع\", \"يطا\", \"الظاهرية\", \"ترقوميا\", \"دير شرف\", \"شقبا\", \n",
    "    \"النفق\", \"شيلو\", \"عطروت\", \"حلميش\", \"المشتل\", \"عقربا\", \"قلنديا\", \n",
    "    \"سبسطية\", \"الفوار\", \"ادوميم\", \"العبيدية\", \"جين صافوت\", \"زواتا\", \n",
    "    \"حومش\", \"دير استيا\", \"العوجا\", \"بيت امر\", \"قباطية\", \"الجلزون\", \n",
    "    \"عطارة\", \"الخروبة\", \"عارورة\", \"الاحراش\", \"عصيرة الشمالية\", \"جيوس\", \"عين يبرود\", \n",
    "    \"عنبتا\", \"الناقورة\", \"الدهيشة\", \"بيت امرين\", \"قوصين\", \"عناتا\", \n",
    "    \"باب الزاوية\", \"الصيرفي\", \"صوريف\", \"ضاحية الريحان\", \"ابو ديس\", \"سالم\", \n",
    "    \"العيسوية\", \"بيت حنينا\", \"البيرة\", \"الاسكانات\", \"الزاوية\", \"النصارية\",\n",
    "    \"واد قانا\", \"المصانع\", \"كفر عقب\", \"بير زيت\", \"عصيرة القبلية\", \"الفندق\"\n",
    "]\n",
    "\n",
    "close_words = [\n",
    "    'مغلق', 'مغلقة', 'وقوف', 'واقفه', 'سكروه', 'مسكره', 'سكر', \n",
    "    'مسكرين', 'متوقفه', 'اغلاق', 'اغلاقه'\n",
    "]\n",
    "open_words = [\n",
    "    'فتح', 'فاضي', 'سالك', 'سالكه', 'فاتحة', 'فاتح', 'سلك', 'فتحت',\n",
    "    'فاتحين', 'بمشو', 'مفتوحة', 'بسلك', 'بمشي', 'مشوا', 'فتحوها', 'سالكات', 'وسلك',\n",
    "    'بالاتجاهين', 'بكل الاتجاهات', 'للداخل والطالع', 'للجهتين'\n",
    "]\n",
    "B_inside = ['للداخل', 'للفايت', 'فايت', 'داخل']\n",
    "B_outside = ['للخارج', 'للطالع', 'طالع']\n",
    "\n",
    "def regex_tokenize_with_similarity(data, location_names, similarity_threshold=80, close_threshold=80, open_threshold=80):\n",
    "    sentence_splitter = re.compile(r'(?<=[.!?]) +')\n",
    "    word_splitter = re.compile(r'[\\u0600-\\u06FF]+|\\d+|\\w+')\n",
    "\n",
    "    sentences_list = []\n",
    "    words_list = []\n",
    "    original_messages = []\n",
    "    word_indices = []\n",
    "    labels = []\n",
    "    similarities = []\n",
    "    sentence_count = 1\n",
    "\n",
    "    for index, message in data['message'].items():\n",
    "        if isinstance(message, str):\n",
    "            sentences = sentence_splitter.split(message.strip())\n",
    "            for sentence in sentences:\n",
    "                words = word_splitter.findall(sentence)\n",
    "                \n",
    "                i = 0\n",
    "                while i < len(words):\n",
    "                    if i + 1 < len(words) and f\"{words[i]} {words[i+1]}\" in location_names:\n",
    "                        labels.extend([\"B-LOC\", \"I-LOC\"])\n",
    "                        similarities.extend([100, 100])  \n",
    "                        \n",
    "                        sentences_list.extend([f\"Sentence: {sentence_count} (Message {index})\"] * 2)\n",
    "                        words_list.extend([words[i], words[i + 1]])\n",
    "                        original_messages.extend([message] * 2)\n",
    "                        word_indices.extend([i + 1, i + 2])\n",
    "                        \n",
    "                        i += 2\n",
    "                        continue\n",
    "                    elif words[i] in location_names:\n",
    "                        labels.append(\"B-LOC\")\n",
    "                        similarities.append(100)\n",
    "                    elif words[i] in B_inside:\n",
    "                        labels.append(\"B-inside\")\n",
    "                        similarities.append(100)\n",
    "                    elif words[i] in B_outside:\n",
    "                        labels.append(\"B-outside\")\n",
    "                        similarities.append(100)\n",
    "                    else:\n",
    "                        max_close_similarity = max(fuzz.ratio(words[i], word) for word in close_words)\n",
    "                        if max_close_similarity >= close_threshold:\n",
    "                            labels.append(\"B-close\")\n",
    "                            similarities.append(max_close_similarity)\n",
    "                        else:\n",
    "                            max_open_similarity = max(fuzz.ratio(words[i], word) for word in open_words)\n",
    "                            if max_open_similarity >= open_threshold:\n",
    "                                labels.append(\"B-open\")\n",
    "                                similarities.append(max_open_similarity)\n",
    "                            else:\n",
    "                                max_loc_similarity = max(fuzz.ratio(words[i], loc) for loc in location_names)\n",
    "                                labels.append(\"B-LOC\" if max_loc_similarity >= similarity_threshold else \"O\")\n",
    "                                similarities.append(max_loc_similarity if max_loc_similarity >= similarity_threshold else 0)\n",
    "\n",
    "                    sentences_list.append(f\"Sentence: {sentence_count} (Message {index})\")\n",
    "                    words_list.append(words[i])\n",
    "                    original_messages.append(message)\n",
    "                    word_indices.append(i + 1)\n",
    "                    i += 1\n",
    "                    \n",
    "                sentence_count += 1\n",
    "\n",
    "    tokenized_df = pd.DataFrame({\n",
    "        'Sentence #': sentences_list,\n",
    "        'Word': words_list,\n",
    "        'Original Message': original_messages,\n",
    "        'Word Index': word_indices,\n",
    "        'label': labels,\n",
    "        'Similarity Score': similarities\n",
    "    })\n",
    "\n",
    "    return tokenized_df\n",
    "\n",
    "# Assume you have `location_names`, `B_inside`, `B_outside`, `close_words`, and `open_words` lists\n",
    "tokenized_df = regex_tokenize_with_similarity(data, location_names)\n",
    "tokenized_df[['Sentence', 'Message']] = tokenized_df['Sentence #'].str.extract(r'Sentence: (\\d+) \\(Message (\\d+)\\)')\n",
    "tokenized_df.drop(columns=['Sentence #'], inplace=True)\n",
    "tokenized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Original Message</th>\n",
       "      <th>Word Index</th>\n",
       "      <th>label</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Message</th>\n",
       "      <th>Word_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شرطه</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6646</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نازله</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10055</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>من</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9903</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عيلي</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>4</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حادث</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5455</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303763</th>\n",
       "      <td>وتفتيش</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>6</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>11390</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303764</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>7</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>6532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303765</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>8</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>6532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303766</th>\n",
       "      <td>عورتا</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>1</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "      <td>7554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303767</th>\n",
       "      <td>لداخل</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "      <td>8502</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word                                   Original Message  Word Index  \\\n",
       "0         شرطه                                 شرطه نازله من عيلي           1   \n",
       "1        نازله                                 شرطه نازله من عيلي           2   \n",
       "2           من                                 شرطه نازله من عيلي           3   \n",
       "3         عيلي                                 شرطه نازله من عيلي           4   \n",
       "4         حادث               حادث سير بعد اشارات شيلو باتجاه عيلي           1   \n",
       "...        ...                                                ...         ...   \n",
       "303763  وتفتيش  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           6   \n",
       "303764   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           7   \n",
       "303765   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           8   \n",
       "303766   عورتا                                        عورتا لداخل           1   \n",
       "303767   لداخل                                        عورتا لداخل           2   \n",
       "\n",
       "        label  Similarity Score Sentence Message  Word_id  label_id  \n",
       "0           O               0.0        1       0     6646         6  \n",
       "1           O               0.0        1       0    10055         6  \n",
       "2           O               0.0        1       0     9903         6  \n",
       "3       B-LOC             100.0        1       0     7574         0  \n",
       "4           O               0.0        2       1     5455         6  \n",
       "...       ...               ...      ...     ...      ...       ...  \n",
       "303763      O               0.0    32976   33988    11390         6  \n",
       "303764      O               0.0    32976   33988     6532         6  \n",
       "303765      O               0.0    32976   33988     6532         6  \n",
       "303766  B-LOC             100.0    32977   33990     7554         0  \n",
       "303767      O               0.0    32977   33990     8502         6  \n",
       "\n",
       "[303768 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "word_encoder = OrdinalEncoder()\n",
    "label_encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform the 'Word' column\n",
    "tokenized_df['Word_id'] = word_encoder.fit_transform(tokenized_df[['Word']])\n",
    "\n",
    "# Fit and transform the 'label' column\n",
    "tokenized_df['label_id'] = label_encoder.fit_transform(tokenized_df[['label']])\n",
    "\n",
    "# Convert the encoded columns to integers for better readability\n",
    "tokenized_df['Word_id'] = tokenized_df['Word_id'].astype(int)\n",
    "tokenized_df['label_id'] = tokenized_df['label_id'].astype(int)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "tokenized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "O            170249\n",
       "B-LOC         63211\n",
       "B-open        41262\n",
       "I-LOC         13916\n",
       "B-close        9043\n",
       "B-outside      3686\n",
       "B-inside       2401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Original Message</th>\n",
       "      <th>Word Index</th>\n",
       "      <th>label</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Message</th>\n",
       "      <th>Word_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شرطه</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6646</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>نازله</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10055</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>من</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9903</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عيلي</td>\n",
       "      <td>شرطه نازله من عيلي</td>\n",
       "      <td>4</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حادث</td>\n",
       "      <td>حادث سير بعد اشارات شيلو باتجاه عيلي</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5455</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303763</th>\n",
       "      <td>وتفتيش</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>6</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>11390</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303764</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>7</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>6532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303765</th>\n",
       "      <td>سياره</td>\n",
       "      <td>الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...</td>\n",
       "      <td>8</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32976</td>\n",
       "      <td>33988</td>\n",
       "      <td>6532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303766</th>\n",
       "      <td>عورتا</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>1</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "      <td>7554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303767</th>\n",
       "      <td>لداخل</td>\n",
       "      <td>عورتا لداخل</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32977</td>\n",
       "      <td>33990</td>\n",
       "      <td>8502</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word                                   Original Message  Word Index  \\\n",
       "0         شرطه                                 شرطه نازله من عيلي           1   \n",
       "1        نازله                                 شرطه نازله من عيلي           2   \n",
       "2           من                                 شرطه نازله من عيلي           3   \n",
       "3         عيلي                                 شرطه نازله من عيلي           4   \n",
       "4         حادث               حادث سير بعد اشارات شيلو باتجاه عيلي           1   \n",
       "...        ...                                                ...         ...   \n",
       "303763  وتفتيش  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           6   \n",
       "303764   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           7   \n",
       "303765   سياره  الكونتير بدايه ازمه باتجاه الجنوب وتفتيش سياره...           8   \n",
       "303766   عورتا                                        عورتا لداخل           1   \n",
       "303767   لداخل                                        عورتا لداخل           2   \n",
       "\n",
       "        label  Similarity Score Sentence Message  Word_id  label_id  \n",
       "0           O               0.0        1       0     6646         6  \n",
       "1           O               0.0        1       0    10055         6  \n",
       "2           O               0.0        1       0     9903         6  \n",
       "3       B-LOC             100.0        1       0     7574         0  \n",
       "4           O               0.0        2       1     5455         6  \n",
       "...       ...               ...      ...     ...      ...       ...  \n",
       "303763      O               0.0    32976   33988    11390         6  \n",
       "303764      O               0.0    32976   33988     6532         6  \n",
       "303765      O               0.0    32976   33988     6532         6  \n",
       "303766  B-LOC             100.0    32977   33990     7554         0  \n",
       "303767      O               0.0    32977   33990     8502         6  \n",
       "\n",
       "[303768 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mehabsulima23\u001b[0m (\u001b[33mehabsulima23-an-najah-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mac2/University/Machine Learning/VS Code /Test_repo/ROADWATCH/W&B/wandb/run-20250125_131301-v38k56r3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH/runs/v38k56r3' target=\"_blank\">CatBoostn_run</a></strong> to <a href='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH' target=\"_blank\">https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH/runs/v38k56r3' target=\"_blank\">https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH/runs/v38k56r3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH/runs/v38k56r3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14a2fb310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ROADWATCH\", name=\"CatBoostn_run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4062474\ttest: 1.4029169\tbest: 1.4029169 (0)\ttotal: 350ms\tremaining: 5m 49s\n",
      "100:\tlearn: 0.0600476\ttest: 0.0492843\tbest: 0.0492843 (100)\ttotal: 17.1s\tremaining: 2m 31s\n",
      "200:\tlearn: 0.0593382\ttest: 0.0487041\tbest: 0.0487041 (200)\ttotal: 32.2s\tremaining: 2m 7s\n",
      "300:\tlearn: 0.0591527\ttest: 0.0486334\tbest: 0.0486317 (291)\ttotal: 47.3s\tremaining: 1m 49s\n",
      "400:\tlearn: 0.0590463\ttest: 0.0486147\tbest: 0.0486137 (370)\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "500:\tlearn: 0.0589935\ttest: 0.0486127\tbest: 0.0486091 (449)\ttotal: 1m 17s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.0589478\ttest: 0.0486017\tbest: 0.0486017 (600)\ttotal: 1m 32s\tremaining: 1m 1s\n",
      "700:\tlearn: 0.0589189\ttest: 0.0486044\tbest: 0.0486017 (600)\ttotal: 1m 47s\tremaining: 45.9s\n",
      "800:\tlearn: 0.0588939\ttest: 0.0485997\tbest: 0.0485993 (797)\ttotal: 2m 2s\tremaining: 30.5s\n",
      "900:\tlearn: 0.0588810\ttest: 0.0486028\tbest: 0.0485993 (797)\ttotal: 2m 17s\tremaining: 15.1s\n",
      "999:\tlearn: 0.0588629\ttest: 0.0485998\tbest: 0.0485993 (797)\ttotal: 2m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.04859930965\n",
      "bestIteration = 797\n",
      "\n",
      "Shrink model to first 798 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac2/Library/Python/3.9/lib/python/site-packages/plotly/matplotlylib/renderer.py:609: UserWarning:\n",
      "\n",
      "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Logloss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Extract evaluation results\u001b[39;00m\n\u001b[1;32m     85\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_evals_result()\n\u001b[0;32m---> 86\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mevals_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     87\u001b[0m eval_losses \u001b[38;5;241m=\u001b[39m evals_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Plot and log loss curves to W&B\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Logloss'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Assuming tokenized_df has 'Word' and 'label' columns\n",
    "X = tokenized_df[['Word']]  # Features (Word column)\n",
    "y = tokenized_df['label']   # Target (label column)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize sample weights (modify if class imbalance exists)\n",
    "sample_weights = np.ones(len(y_train), dtype=float)\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    cat_features=[0],  # Specify 'Word' as categorical\n",
    "    loss_function='MultiClass',\n",
    "    custom_metric=['Accuracy', 'MultiClass']  # MultiClass metric replaces Logloss\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    verbose=100,  # Log progress every 100 iterations\n",
    "    sample_weight=sample_weights\n",
    ")\n",
    "\n",
    "# Predict probabilities and labels\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Retrieve unique class names directly from `y`\n",
    "class_names = np.unique(y)\n",
    "\n",
    "# Calculate ROC curve and AUC for each class\n",
    "n_classes = len(class_names)\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr[i], tpr[i], _ = roc_curve((y_test == class_name).astype(int), y_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Log classification report to W&B\n",
    "class_report = classification_report(\n",
    "    y_test, y_pred, target_names=class_names, output_dict=True\n",
    ")\n",
    "wandb.log({\"classification_report\": class_report})\n",
    "\n",
    "# Log confusion matrix to W&B\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "\n",
    "# Log ROC curves to W&B\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "wandb.log({\"roc_curve\": plt})\n",
    "plt.close()  # Close the figure after logging\n",
    "\n",
    "# Log training and test accuracy\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "wandb.log({\"train_accuracy\": train_accuracy, \"test_accuracy\": test_accuracy})\n",
    "\n",
    "# Extract evaluation results\n",
    "evals_result = model.get_evals_result()\n",
    "train_losses = evals_result['learn']['Logloss']\n",
    "eval_losses = evals_result['validation']['Logloss']\n",
    "\n",
    "# Plot and log loss curves to W&B\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Logloss')\n",
    "plt.plot(eval_losses, label='Validation Logloss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Logloss')\n",
    "plt.title('Training and Validation Logloss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "wandb.log({\"loss_curve\": plt})\n",
    "plt.close()  # Close the figure after logging\n",
    "\n",
    "# Log accuracy curves if available\n",
    "if 'Accuracy' in evals_result['learn']:\n",
    "    train_acc_curve = evals_result['learn']['Accuracy']\n",
    "    val_acc_curve = evals_result['validation']['Accuracy']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_acc_curve, label='Training Accuracy')\n",
    "    plt.plot(val_acc_curve, label='Validation Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    wandb.log({\"accuracy_curve\": plt})\n",
    "    plt.close()  # Close the figure after logging\n",
    "\n",
    "# Finish the W&B run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ehabsulima23-an-najah-national-university/ROADWATCH/runs/zdpgsceo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15cdcfe80>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ROADWATCH\", name=\"LOG_REG_TargetEncoding_run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac2/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/mac2/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/mac2/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/mac2/Library/Python/3.9/lib/python/site-packages/plotly/matplotlylib/renderer.py:609: UserWarning:\n",
      "\n",
      "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>B-LOC_f1-score</td><td>▁</td></tr><tr><td>B-LOC_precision</td><td>▁</td></tr><tr><td>B-LOC_recall</td><td>▁</td></tr><tr><td>B-close_f1-score</td><td>▁</td></tr><tr><td>B-close_precision</td><td>▁</td></tr><tr><td>B-close_recall</td><td>▁</td></tr><tr><td>B-inside_f1-score</td><td>▁</td></tr><tr><td>B-inside_precision</td><td>▁</td></tr><tr><td>B-inside_recall</td><td>▁</td></tr><tr><td>B-open_f1-score</td><td>▁</td></tr><tr><td>B-open_precision</td><td>▁</td></tr><tr><td>B-open_recall</td><td>▁</td></tr><tr><td>B-outside_f1-score</td><td>▁</td></tr><tr><td>B-outside_precision</td><td>▁</td></tr><tr><td>B-outside_recall</td><td>▁</td></tr><tr><td>I-LOC_f1-score</td><td>▁</td></tr><tr><td>I-LOC_precision</td><td>▁</td></tr><tr><td>I-LOC_recall</td><td>▁</td></tr><tr><td>O_f1-score</td><td>▁</td></tr><tr><td>O_precision</td><td>▁</td></tr><tr><td>O_recall</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>B-LOC_f1-score</td><td>0.90339</td></tr><tr><td>B-LOC_precision</td><td>0.8596</td></tr><tr><td>B-LOC_recall</td><td>0.95188</td></tr><tr><td>B-close_f1-score</td><td>0</td></tr><tr><td>B-close_precision</td><td>0</td></tr><tr><td>B-close_recall</td><td>0</td></tr><tr><td>B-inside_f1-score</td><td>0</td></tr><tr><td>B-inside_precision</td><td>0</td></tr><tr><td>B-inside_recall</td><td>0</td></tr><tr><td>B-open_f1-score</td><td>0.88119</td></tr><tr><td>B-open_precision</td><td>0.78762</td></tr><tr><td>B-open_recall</td><td>1</td></tr><tr><td>B-outside_f1-score</td><td>0</td></tr><tr><td>B-outside_precision</td><td>0</td></tr><tr><td>B-outside_recall</td><td>0</td></tr><tr><td>I-LOC_f1-score</td><td>0</td></tr><tr><td>I-LOC_precision</td><td>0</td></tr><tr><td>I-LOC_recall</td><td>0</td></tr><tr><td>O_f1-score</td><td>0.95129</td></tr><tr><td>O_precision</td><td>0.92286</td></tr><tr><td>O_recall</td><td>0.98153</td></tr><tr><td>test_accuracy</td><td>0.88467</td></tr><tr><td>train_accuracy</td><td>0.88369</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logistic_regression_Target_encoding</strong> at: <a href='https://wandb.ai/ehabsulima23-an-najah-national-university/logistic_regression/runs/n3z7x1bt' target=\"_blank\">https://wandb.ai/ehabsulima23-an-najah-national-university/logistic_regression/runs/n3z7x1bt</a><br> View project at: <a href='https://wandb.ai/ehabsulima23-an-najah-national-university/logistic_regression' target=\"_blank\">https://wandb.ai/ehabsulima23-an-najah-national-university/logistic_regression</a><br>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250124_155151-n3z7x1bt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Target Encoding\n",
    "target_encoding = tokenized_df.groupby('Word')['label_id'].mean()\n",
    "tokenized_df['Word_id_encoded'] = tokenized_df['Word'].map(target_encoding)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tokenized_df['Word_id_encoded'].values.reshape(-1, 1),  # Reshape for compatibility\n",
    "    tokenized_df['label_id'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities and labels\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Decode class names\n",
    "class_names = label_encoder.inverse_transform(np.arange(len(label_encoder.categories_[0])).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate ROC curve and AUC for each class\n",
    "n_classes = len(np.unique(y_train))\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Log classification report\n",
    "class_report = classification_report(\n",
    "    y_test, y_pred, target_names=class_names, output_dict=True\n",
    ")\n",
    "wandb.log({\"classification_report\": class_report})\n",
    "\n",
    "# Log confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "\n",
    "# Log ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Log ROC curve to WandB\n",
    "wandb.log({\"roc_curve\": plt})\n",
    "\n",
    "# Log training accuracy\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "wandb.log({\"train_accuracy\": train_accuracy, \"test_accuracy\": test_accuracy})\n",
    "\n",
    "# Log precision and recall per class\n",
    "for cls, metrics in class_report.items():\n",
    "    if cls in class_names:  # Ignore overall averages (precision/recall/F1-score)\n",
    "        wandb.log({\n",
    "            f\"{cls}_precision\": metrics[\"precision\"],\n",
    "            f\"{cls}_recall\": metrics[\"recall\"],\n",
    "            f\"{cls}_f1-score\": metrics[\"f1-score\"]\n",
    "        })\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
